<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="ko">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Hello, World!">
<meta property="og:type" content="website">
<meta property="og:title" content="Libskim">
<meta property="og:url" content="https://libskim.github.io/index.html">
<meta property="og:site_name" content="Libskim">
<meta property="og:description" content="Hello, World!">
<meta property="og:locale" content="ko">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Libskim">
<meta name="twitter:description" content="Hello, World!">





  
  
  <link rel="canonical" href="https://libskim.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Libskim</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="ko">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Libskim</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Seunghyun's Library</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>홈</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>카테고리<span class="badge">1</span></a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>태그<span class="badge">3</span></a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    
  
  

  

  <a href="https://github.com/libskim" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://libskim.github.io/2019/06/05/luna16-preprocessing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Seunghyun Kim">
      <meta itemprop="description" content="Hello, World!">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Libskim">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/05/luna16-preprocessing/" class="post-title-link" itemprop="url">LUNA16 의료영상 데이터 전처리 (1)</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">작성일</span>
              

              
                
              

              <time title="Post created: 2019-06-05 00:39:57" itemprop="dateCreated datePublished" datetime="2019-06-05T00:39:57+09:00">2019-06-05</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Updated at: 2019-06-07 15:33:27" itemprop="dateModified" datetime="2019-06-07T15:33:27+09:00">2019-06-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Medical/" itemprop="url" rel="index"><span itemprop="name">Medical</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="I-들어가며"><a href="#I-들어가며" class="headerlink" title="I. 들어가며"></a>I. 들어가며</h2><p>실험실에서 딥러닝을 의료 영상 분석에 적용할 프로젝트를 고민한 적이 있었고, 그 일환으로 폐(lung) 컴퓨터 단층촬영(CT: computed tomography) 영상에서 결절 혹은 암 따위의 오브젝트를 판별하기 위한 연구가 계획되었다. 당시 나는 <strong><a href="https://luna16.grand-challenge.org/" target="_blank" rel="noopener">LUNA16</a></strong> 챌린지를 중심으로 딥러닝 모델에 투입될 데이터의 전처리를 맡았는데, 이와 유사한 기존의 연구나 프로젝트들이 상당히 많았기에 진행에 큰 어려움은 없었으나 그 과정들이 단순치 않았다.</p>
<p>나는 이 연구를 통해 처음으로 의료 AI 분야에 관심을 갖게 되었는데, 딥러닝 모델의 구성이나 하이퍼파라메터 조정보다도 데이터가 가진 변수나 속성을 잘 파악하고 질적인 한계를 극복하는 것이 훨씬 해결하기 어려운 분야임을 느꼈다. 특히 이것이 환자의 생명과 관련된 문제였기에 노이즈 추가나 GAN을 통한 이미지 생성 등 데이터 증강 기법 적용이 어떤 결과를 초래할지 전혀 유추할 수 없었으며, 심지어 10-fold cross-validation을 거친 false positive rate가 낮게 나왔음에도 심적으로 신뢰되지 않았다. 이런 심오함이 오히려 호기심을 자극하는 듯 하다.</p>
<h2 id="II-데이터-세트"><a href="#II-데이터-세트" class="headerlink" title="II. 데이터 세트"></a>II. 데이터 세트</h2><p>LUNA16은 폐 결절(nodule)과 관련된 두 가지 트랙을 챌린지 종목으로 채택하고 있다. 하나는 영상에서 결절로 의심되는 영역을 탐지하는 <strong>Nodule detection</strong> 이고, 다른 하나는 주어진 결절 후보들의 거짓 양성 분류율을 낮추는 <strong>False positive reduction</strong> 이다. LUNA16 공식 홈페이지에서 데이터 세트를 내려 받을 수 있는 링크를 제공하며, Data 섹션에 설명된 데이터 세트의 구조를 요약하면 다음과 같다.</p>
<ul>
<li><strong>subset0.zip ~ subset9.zip</strong>: 모든 CT 영상들이 포함된 zip 파일 10개.</li>
<li><strong>annotations.csv</strong>: 실제 결절 위치가 저장된 csv 파일. Nodule detection 트랙에서 사용.</li>
<li><strong>sampleSubmission.csv</strong>: 결과 제출용 파일 양식.</li>
<li><strong>candidates.csv</strong>: 결절 후보(결절 또는 비결절)들의 정보가 저장된 csv 파일. 이 파일 대신 candidates_V2.csv 사용을 권고.</li>
<li><strong>candidates_V2.csv</strong>: 결절 후보(결절 또는 비결절)들의 정보가 저장된 csv 파일. False positive reduction 트랙에서 사용.</li>
<li><strong>evaluation script</strong>: 결과 검증용 스크립트.</li>
<li><strong>lung segmentation</strong>: 자동 알고리즘으로 계산된 폐 분할 이미지들의 디렉토리.</li>
<li><strong>additional_annotations.csv</strong>: 추가 결절들이 포함된 csv 파일.</li>
</ul>
<p>우리는 CNN(convolutional neural network)을 이용해 결절의 이진 분류 성능 향상시키고자 두 번째 트랙과 관련된 파일인 subset*.zip과 candidates_V2.csv를 사용하였다. 참고로 subset*.zip은 개개의 압축 용량이 6~8GB, 압축 해제 시 12GB 이상이므로 넉넉한 시간과 여유 공간이 필요하다.</p>
<h2 id="III-파이썬-및-라이브러리"><a href="#III-파이썬-및-라이브러리" class="headerlink" title="III. 파이썬 및 라이브러리"></a>III. 파이썬 및 라이브러리</h2><p>파이썬은 다른 프로그래밍 언어보다 접근성이 좋았고 훌륭한 딥러닝 라이브러리들이 이 언어를 지원하였기에 사용하지 않을 이유가 없었다. 사용된 파이썬 버전은 3.6.5 이고 라이브러리 목록은 아래와 같다.</p>
<ul>
<li><strong>NumPy 1.16.0</strong>: 여러 가지 계산 함수 활용</li>
<li><strong>Pandas 0.23.4</strong>: candidates_V2.csv 파일 처리</li>
<li><strong>SciPy 1.2.0</strong>: 이미지 인터폴레이션</li>
<li><strong>SimpleITK 1.2.0</strong>: CT 영상 파일(*.mhd) 처리</li>
<li><strong>Matplotlib 3.0.2</strong>: 이미지 시각화</li>
<li><strong>tqdm 4.29.1</strong>: 작업 진행률 모니터링(옵션)</li>
</ul>
<p>개발자는 리눅스 터미널이나 윈도우 명령 프롬프트에서 pip 명령어를 통해 이들을 개별적으로 설치하거나, 아니면 아나콘다를 사용할 수도 있다. 가상 환경(virtual environment)이나 미리 세팅된 도커(docker) 컨테이너도 선택지가 될 수 있으니 자세한 내용은 해당 공식 홈페이지를 참고하는 것이 좋다.</p>
<h2 id="IV-전처리"><a href="#IV-전처리" class="headerlink" title="IV. 전처리"></a>IV. 전처리</h2><h3 id="1-작업-디렉토리-구성"><a href="#1-작업-디렉토리-구성" class="headerlink" title="1) 작업 디렉토리 구성"></a>1) 작업 디렉토리 구성</h3><p>디렉토리 구성은 아래와 같다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">/notebooks</span><br><span class="line">    ├ /datasets</span><br><span class="line">    │    └ /luna16</span><br><span class="line">    │        ├ candidates_V2.csv</span><br><span class="line">    │        ├ /subset0</span><br><span class="line">    │        │    ├ 1.3.6.1....1260.mhd</span><br><span class="line">    │        │    ├ 1.3.6.1....1260.raw</span><br><span class="line">    │        │    └ ...</span><br><span class="line">    │        ├ /subset1</span><br><span class="line">    │        ├ /subset2</span><br><span class="line">    │        ├ ...</span><br><span class="line">    │        └ /subset9</span><br><span class="line">    └ /luna16</span><br><span class="line">         └ preprocessing.ipynb</span><br></pre></td></tr></table></figure>

<p>최상위 디렉토리 <strong>/notebooks</strong>를 기준으로 <strong>/datasets/luna16</strong> 디렉토리에는 CT 영상 내 결절 후보들의 정보를 담고있는 파일 candidates_V2.csv 및 실제 CT 영상 파일이 위치한 subset* 디렉토리들이 들어있다. 이 포스트에서는 테스트 편의를 위해 subset0 ~ subset9 중 subset0만을 사용하며, 전처리 코드가 실행될 주피터 노트북 파일은 <strong>/luna16/preprocessing.ipynb</strong> 이다.</p>
<h3 id="2-결절-후보들의-정보-살펴보기"><a href="#2-결절-후보들의-정보-살펴보기" class="headerlink" title="2) 결절 후보들의 정보 살펴보기"></a>2) 결절 후보들의 정보 살펴보기</h3><p>파일 candidates_V2.csv에 저장된 전체 데이터 개수 및 컬럼에 대한 설명은 공식 홈페이지에 기재되어 있다. 그러나 내가 직접 확인하는 것과는 또 다른 느낌이므로 직접 확인해 보았다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> SimpleITK <span class="keyword">as</span> sitk</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> interpolation</span><br><span class="line"></span><br><span class="line">csv_file = <span class="string">'../datasets/luna16/candidates_V2.csv'</span></span><br><span class="line">df = pd.read_csv(csv_file)</span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/1.png">

<p>인덱스 0부터 754,974까지 총 754,975개의 행(결절 후보)이 있으며, 각 행은 5개 컬럼(non-null)으로 구성된 정보를 갖는다. 컬럼 coordX, coordY, 그리고 coordZ는 3차원 공간(physical space)에서 결절의 좌표를 나타내는 실수형(float64) 자료이고, seriesuid와 class는 각각 CT 영상 식별자, 클래스(결절 또는 비결절)를 의미한다. 인덱스 기준 상위 5개 행만 출력해 보겠다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/2.png">

<p>컬럼 seriesuid는 각 행의 결절 후보가 소속된 *.mhd 파일을 가리킨다. 그러나 이것만으론 각 subset 별 *.mhd의 개수와 결절 또는 비결절의 개수가 확인되지 않는다. 코드 몇 줄 더 작성해서 실행해 보니,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">subsets = sorted(glob(<span class="string">'../datasets/luna16/subset*'</span>))</span><br><span class="line">mhd_files = []</span><br><span class="line"><span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">    subset_mhd_files = glob(os.path.join(subset, <span class="string">'*.mhd'</span>))</span><br><span class="line">    <span class="keyword">for</span> mhd_file <span class="keyword">in</span> subset_mhd_files:</span><br><span class="line">        mhd_files.append(mhd_file)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(uid)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> mhd_file <span class="keyword">in</span> mhd_files:</span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">in</span> mhd_file: <span class="keyword">return</span> mhd_file.split(<span class="string">'/'</span>)[<span class="number">-2</span>]</span><br><span class="line"></span><br><span class="line">df[<span class="string">'dir'</span>] = df[<span class="string">'seriesuid'</span>].apply(helper)</span><br><span class="line">df = df.dropna()</span><br><span class="line"></span><br><span class="line">df.sample(n=<span class="number">10</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/3.png">

<p>데이터 세트의 크기가 커서 처리에 수 초가 걸렸다. 각 결절 후보의 seriesuid를 이용해 해당 결절이 위치한 subset 이름을 새로운 컬럼 dir에 추가한 후, 모집단에서 10개의 샘플을 랜덤 샘플링 해보았다(랜덤시드 1). 모든 행에 대한 세부 정보를 살펴보면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'1. DataFrameInfo'</span>)</span><br><span class="line">print(<span class="string">' - tot seriesuid:'</span>, len(df[<span class="string">'seriesuid'</span>].value_counts()))</span><br><span class="line">print(<span class="string">' - tot subsets:'</span>, len(df[<span class="string">'dir'</span>].value_counts()))</span><br><span class="line">cls0, cls1 = df[<span class="string">'class'</span>].value_counts()</span><br><span class="line">print(<span class="string">' - tot rows(nodule:non-nodule):'</span>, len(df), <span class="string">'(%d:%d)'</span> % (cls1, cls0))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\n2. SubsetInfo [subset: rows(nodule:non-nodule)]'</span>)</span><br><span class="line"><span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">    subset_name = subset.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    subset_df = df[df[<span class="string">'dir'</span>] == subset_name]</span><br><span class="line">    rows = len(subset_df)</span><br><span class="line">    cls0, cls1 = subset_df[<span class="string">'class'</span>].value_counts()</span><br><span class="line">    print(<span class="string">' - '</span> + subset_name + <span class="string">':'</span>, rows, <span class="string">'(%d:%d)'</span> % (cls1, cls0))</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/4.png">

<p>총 888개의 seriesuid(*.mhd files)가 존재, 클래스는 0(비결절)과 1(결절)로 분류되고 개수는 각각 753,418개, 1,557개이다. 결절 비결절 데이터 개수 비율이 대략 1:483으로 굉장히 언밸런스하고 이러한 양상이 모든 subset에서 나타난다. 딥러닝에서 학습데이터 불균형은 매우 흔하지만 수 백 배수 이상 차이가 난다면 모델의 일반화 성능 향상을 기대하기 어렵다. 이러한 상황에선 어느 한 쪽의 데이터를 다른 쪽의 데이터 개수에 맞추는 업샘플링(upsampling) 또는 다운샘플링(downsampling)을 고려할 수 있다. 연구가 진행될 당시, 우리는 결절 1,557개를 비결절 개수와 비슷해지도록 데이터 증강(data augmentation) 작업을 추가하기로 하였고, 나는 그 코드를 1차 전처리 작업이 완료된 후에 작성했었다. 추후 이 내용을 포스팅할 예정이다.</p>
<h3 id="3-CT-영상-살펴보기"><a href="#3-CT-영상-살펴보기" class="headerlink" title="3) CT 영상 살펴보기"></a>3) CT 영상 살펴보기</h3><p>돌이켜 보면 전처리 작업 초기에 나는 CT 영상이 단순히 이미지들의 묶음으로 구성 되었을 것이다 생각했었는데 의외로 복잡한 개념을 포함하고 있어 당황했던 기억이 난다. 특히 <strong>Voxel space</strong> 와 <strong>Physical space</strong> 의 상호변환과 <strong>Slicing thickness</strong> 에 대한 개념 자체가 없었기에 꽤나 삽질했다. 내려받은 CT 영상이 *.dcm 이 아닌  *.mhd 파일 확장자(Insight Meta-Image)였다는 것도 한 몫 했다. 나는 이것들의 관계나 차이를 아직 명확히 알지 못하기 때문에 세부 내용은 다시 업데이트 할 것이다. 지난 기억을 정리하는 지금 시점에선 정말 어려울 것 하나 없는 과정인데 왜 그렇게 애먹었는지 모르겠다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="number">42</span> <span class="comment"># in subset0</span></span><br><span class="line">img = sitk.ReadImage(mhd_files[index])</span><br><span class="line">imgarr = sitk.GetArrayFromImage(img)</span><br><span class="line"></span><br><span class="line">img_axial = imgarr[len(imgarr)//<span class="number">2</span>] <span class="comment"># imgarr[len(...)//2, :, :]과 동일</span></span><br><span class="line">plt.title(<span class="string">"Axial shape:"</span> + str(np.shape(img_axial)))</span><br><span class="line">plt.imshow(img_axial, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/5.png">

<p>라인 1과 2에서 *.mhd 파일 888개 중 43번째 파일(subset0 하위에 존재)의 raw 데이터를 변수 img에 저장하였고, 라인 3에서 이를 리스트(배열)로 다시 변환(from physical space to voxel space)하여 변수 imgarr에 저장하고 있다. 여기서 입력된 의료 영상은 2차원 단층 영상의 시리즈(series) 데이터이므로 imgarr은 3차원 리스트가 된다. 따라서 2차원 횡단면(axial plane) 영상을 얻기 위해 라인 5에서 3차원 리스트 슬라이싱을 사용하였고, 그 영상을 변수 img_axial에 저장하였다. 라인 6~7은 이를 출력하는 코드다. 출력 이미지만 보면 라인 3에서 이미 양자화(quantization)가 진행되었으므로 이 상태 그대로 직렬화(serialization)하면 될 것 같지만 그건 큰 오산이다. 다음 코드를 보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img_sagittal = imgarr[:, :, len(imgarr[<span class="number">0</span>][<span class="number">0</span>])//<span class="number">2</span>]</span><br><span class="line">plt.title(<span class="string">"Sagittal shape:"</span> + str(np.shape(img_sagittal)))</span><br><span class="line">plt.imshow(img_sagittal, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/6.png">

<p>위 출력은 동일한 imgarr에서 시상면(sagittal plane)을 슬라이싱하여 출력한 결과이다. 횡단면 이미지와 달리, 흉부 길이가 비정상적으로 짧으며 그레이 레벨(gray level) 범위 또한 달라 보인다. 이는 관상면(coronal plane) 이미지 또한 마찬가지다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img_coronal = imgarr[:, len(imgarr[<span class="number">0</span>])//<span class="number">2</span>, :]</span><br><span class="line">plt.title(<span class="string">"Coronal shape:"</span> + str(np.shape(img_coronal)))</span><br><span class="line">plt.imshow(img_coronal, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/7.png">

<p>왜 이런 결과가 나타날까? 바로 <strong>Slicing thickness</strong> 때문이다. 이 개념은 식빵을 칼로 자르는 것에 비유하여 쉽게 설명할 수 있다. 잘려진 빵의 단면을 앞서 보았던 횡단면 영상이라고 가정해보자. 이 영상들이 자연스럽게 연속적으로 보이도록 만드려면 빵을 아주 얇게 썰어야 할 것이다. 그러나 현실적으로 두께 조절에 어려운 부분이 있는데 <strong><a href="http://www.icrp.org/docs/P087_Korean_CT.pdf" target="_blank" rel="noopener">국제방사선방호위원회 간행물</a></strong> 에 따르면 CT 촬영 시 슬라이스 두께에 따라 환자가 받는 방사선 피폭 정도가 달라진다고 하니, 이유야 어찌됐건 우리는 슬라이싱 두께를 고려하여 인터폴레이션(interpolation)을 수행해야 하겠다.</p>
<p>그러나 새로운 복병이 기다리고 있었으니, 바로 candidates_V2.csv에 저장된 결절 후보의 좌표다. imgarr이 재배열된다면 각 요소의 위치도 완전히 달라지므로 동일한 변환 로직을 좌표에도 적용해 주어야 할텐데 어떻게 할까? 게다가 데이터프레임에 저장된 coordX, coordY, 그리고 coordZ 값은 Physical space의 좌표(실수형)다. 내가 여기서 가장 많은 시간을 소모했다.</p>
<h3 id="4-리샘플-및-노멀라이즈"><a href="#4-리샘플-및-노멀라이즈" class="headerlink" title="4) 리샘플 및 노멀라이즈"></a>4) 리샘플 및 노멀라이즈</h3><p>이제 Slicing thickness를 고려한 리샘플 및 노멀라이즈 방법에 대하여 기술한다. 적용 대상은 imgarr과 결절 후보 좌표값들이다. 아래 코드는 리샘플 및 노멀라이즈 함수를 구현한 것으로, 리샘플 구현부는 <strong><a href="https://www.kaggle.com/" target="_blank" rel="noopener">Kaggle</a></strong> 에서 활동하는 <strong><a href="https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial" target="_blank" rel="noopener">Guido Zuidhof</a></strong> 의 문서를 참고하여 작성하였음을 밝힌다(세부 내용이 궁금하면 링크를 참조할 것).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_real_resize_factor</span><span class="params">(shape, spacing, adj_spacing=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> adj_spacing <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        adj_spacing = list(np.ones_like(shape))</span><br><span class="line">    new_shape = np.round(shape * (spacing / adj_spacing))</span><br><span class="line">    real_resize_factor = new_shape / shape</span><br><span class="line">    <span class="keyword">return</span> real_resize_factor</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resample</span><span class="params">(imgarr, spacing)</span>:</span></span><br><span class="line">    real_resize_factor = _real_resize_factor(imgarr.shape, spacing)</span><br><span class="line">    spacing = spacing / real_resize_factor</span><br><span class="line">    imgarr = interpolation.zoom(imgarr, real_resize_factor, mode=<span class="string">'nearest'</span>)</span><br><span class="line">    <span class="keyword">return</span> imgarr, spacing</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(imgarr, norm_min, norm_max)</span>:</span></span><br><span class="line">    imgarr = np.where(imgarr &lt; norm_min, norm_min, imgarr)</span><br><span class="line">    imgarr = np.where(imgarr &gt; norm_max, norm_max, imgarr)</span><br><span class="line">    imgarr = (imgarr + abs(norm_min)) / (abs(norm_min) + abs(norm_max))</span><br><span class="line">    <span class="keyword">return</span> imgarr</span><br></pre></td></tr></table></figure>

<p>함수 _real_resize_factor()는  축(z, y, x)별 리사이징 계수를 반환하고, 함수 resample()은 이를 이용하여 재계산된(변환된) imgarr 과 spacing 정보를 반환한다. 함수 normalize()는 imgarr 의 픽셀값을 미리 지정된 상하한에 따라 조절하는데, 하운스필드 유닛(HU: Hounsfield Unit) 스케일에 맞게 처리하여야 한다. 리샘플 및 노멀라이즈를 imgarr에 적용하는 코드는 아래와 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">origin = np.array(img.GetOrigin())[::<span class="number">-1</span>]</span><br><span class="line">spacing = np.array(img.GetSpacing())[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">imgarr, spacing = resample(imgarr, spacing)</span><br><span class="line">imgarr = normalize(imgarr, <span class="number">-1000</span>, <span class="number">400</span>)</span><br><span class="line"></span><br><span class="line">img_titles = [<span class="string">'Axial'</span>, <span class="string">'Sagittal'</span>, <span class="string">'Coronal'</span>]</span><br><span class="line">img_planes = [</span><br><span class="line">    imgarr[len(imgarr)//<span class="number">2</span>],</span><br><span class="line">    imgarr[:, :, len(imgarr[<span class="number">0</span>][<span class="number">0</span>])//<span class="number">2</span>],</span><br><span class="line">    imgarr[:, len(imgarr[<span class="number">0</span>])//<span class="number">2</span>, :]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(img_titles)):</span><br><span class="line">    axes[i].set_title(img_titles[i] + <span class="string">' shape: '</span> + str(img_planes[i].shape))</span><br><span class="line">    axes[i].imshow(img_planes[i], cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/8.png">

<p>라인 1과 2는 *.mhd 파일에 저장된 origin 및 spacing 정보(slicing thickness 등 축 별 간격 정보)를 가져오는 것이고, 그 다음 라인부터는 이에 따라 리샘플 및 노멀라이즈 적용 후 이미지를 출력하는 과정이다. 앞선 출력들보다 훨씬 자연스러움을 알 수 있다. 다음은 같은 방법으로 좌표 정보를 수정하는 코드이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = df[df[<span class="string">'seriesuid'</span>]==mhd_files[index].split(<span class="string">'/'</span>)[<span class="number">-1</span>][:<span class="number">-4</span>]]</span><br><span class="line">df = df[df[<span class="string">'class'</span>]==<span class="number">1</span>]</span><br><span class="line">df = df.drop(labels=[<span class="string">'seriesuid'</span>, <span class="string">'dir'</span>], axis=<span class="number">1</span>)</span><br><span class="line">df[<span class="string">'file'</span>] = mhd_files[index]</span><br><span class="line">df[<span class="string">'vcoordX'</span>], df[<span class="string">'vcoordY'</span>], df[<span class="string">'vcoordZ'</span>] = [np.nan] * <span class="number">3</span></span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/9.png">

<p>데이터 규모가 크므로 특정 mhd 파일의 결절(class=1) 행을 제외한 모든 행은 제거한 후, 파일 경로 및 voxel space 좌표가 저장될 새로운 컬럼들을 추가하고 불필요한 컬럼은 삭제하였다. 이 mhd 파일에는 실제 결절이 5개(우연히 df.head()의 출력 개수와 맞아 떨어졌다) 존재함을 확인할 수 있다. 다음은 origin과 리샘플 함수로 얻어진 새로운 spacing을 활용하여 복셀 좌표를 계산하는 코드이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    center = np.array([row[<span class="string">'coordZ'</span>], row[<span class="string">'coordY'</span>], row[<span class="string">'coordX'</span>]])</span><br><span class="line">    vcenter = np.rint((center - origin) / spacing)</span><br><span class="line">    df.at[i, <span class="string">'vcoordZ'</span>] = vcenter[<span class="number">0</span>]</span><br><span class="line">    df.at[i, <span class="string">'vcoordY'</span>] = vcenter[<span class="number">1</span>]</span><br><span class="line">    df.at[i, <span class="string">'vcoordX'</span>] = vcenter[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">df = df.drop(labels=[<span class="string">'coordX'</span>, <span class="string">'coordY'</span>, <span class="string">'coordZ'</span>], axis=<span class="number">1</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/10.png">

<h3 id="5-결절-영역-추출하기"><a href="#5-결절-영역-추출하기" class="headerlink" title="5) 결절 영역 추출하기"></a>5) 결절 영역 추출하기</h3><p>드디어 1차 전처리의 막바지에 이르렀다. 리샘플된 imgarr 및 voxel coordinates를 이용하여 실제 결절 영역을 크롭할 것이다. 다음을 보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(imgarr, pos, size, margin)</span>:</span></span><br><span class="line">    shape = imgarr.shape</span><br><span class="line">    half_size = np.rint(size / <span class="number">2</span>)</span><br><span class="line">    vmin = (pos - half_size) - margin</span><br><span class="line">    vmin = [np.max([<span class="number">0</span>, int(i)]) <span class="keyword">for</span> i <span class="keyword">in</span> vmin]</span><br><span class="line">    vmax = vmin + size + (margin * <span class="number">2</span>)</span><br><span class="line">    vmax = [np.min([ax, int(i)]) <span class="keyword">for</span> ax, i <span class="keyword">in</span> zip(shape, vmax)]</span><br><span class="line">    <span class="keyword">return</span> imgarr[vmin[<span class="number">0</span>]:vmax[<span class="number">0</span>], vmin[<span class="number">1</span>]:vmax[<span class="number">1</span>], vmin[<span class="number">2</span>]:vmax[<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wrap</span><span class="params">(cand_arr, size)</span>:</span></span><br><span class="line">    shape = cand_arr.shape</span><br><span class="line">    wrapped = np.ones(size) * np.min(cand_arr)</span><br><span class="line">    vmin = np.rint((size - shape) / <span class="number">2</span>)</span><br><span class="line">    vmin = np.array([int(i) <span class="keyword">for</span> i <span class="keyword">in</span> vmin])</span><br><span class="line">    vmax = vmin + shape</span><br><span class="line">    wrapped[vmin[<span class="number">0</span>]:vmax[<span class="number">0</span>], vmin[<span class="number">1</span>]:vmax[<span class="number">1</span>], vmin[<span class="number">2</span>]:vmax[<span class="number">2</span>]] = cand_arr</span><br><span class="line">    <span class="keyword">return</span> wrapped</span><br></pre></td></tr></table></figure>

<p>함수 extract()는 pos(position, 결절 위치를 의미)를 중심으로 size와 margin에 따라 결절 영역(이하 큐브)을 크롭하며, 함수 wrap()은 큐브의 일부가 imgarr 공간을 벗어나는 경우(결절 좌표와 imgarr 외곽 사이의 거리가 결절 반경보다 짧을 때) 큐브 크기가 달라지기 때문에 이를 일정하게 맞추기 위해 사용된다. 함수 내용은 어려울 것이 없으니 설명하지 않는다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">size, margin = np.array([<span class="number">56</span>, <span class="number">56</span>, <span class="number">56</span>]), <span class="number">0</span></span><br><span class="line"></span><br><span class="line">cubes = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    vcenter = np.array([row[<span class="string">'vcoordZ'</span>], row[<span class="string">'vcoordY'</span>], row[<span class="string">'vcoordX'</span>]])</span><br><span class="line">    cand_arr = extract(imgarr, vcenter, size, margin)</span><br><span class="line">    cand_arr = wrap(cand_arr, size)</span><br><span class="line">    cubes.append(cand_arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, cube <span class="keyword">in</span> enumerate(cubes):</span><br><span class="line">    print(<span class="string">'cube-%d:'</span> % i, cube.shape)</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/11.png">

<p>라인 1은 크롭될 큐브의 사이즈를 세 축 모두 56으로 지정하였고, 마진은 주지 않았다. 라인 10~11은 (리샘플 및 노멀라이즈 단계에서 보았던) 크롭된 큐브 5개에 대한 형상 정보를 출력한다. 크롭이 완료되었으니 이제 결절들의 면상을 한번 관찰해본다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plane = [<span class="string">'ax'</span>, <span class="string">'sg'</span>, <span class="string">'cn'</span>] <span class="comment"># axial, sagittal, coronal</span></span><br><span class="line">phase = [<span class="number">0.45</span>, <span class="number">0.475</span>, <span class="number">0.5</span>, <span class="number">0.525</span>, <span class="number">0.55</span>]</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(len(phase), len(plane)*<span class="number">5</span>, figsize=(<span class="number">35</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(phase)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(plane)*<span class="number">5</span>):</span><br><span class="line">        idx = j // <span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> j % <span class="number">3</span> == <span class="number">0</span>:   <span class="comment"># axial plane</span></span><br><span class="line">            img = cubes[idx][int(len(cubes[idx])*phase[i]),:,:]</span><br><span class="line">        <span class="keyword">elif</span> j % <span class="number">3</span> == <span class="number">1</span>: <span class="comment"># sagittal plane</span></span><br><span class="line">            img = cubes[idx][:,:,int(len(cubes[idx][<span class="number">0</span>][<span class="number">0</span>])*phase[i])]</span><br><span class="line">        <span class="keyword">else</span>:            <span class="comment"># coronal plane</span></span><br><span class="line">            img = cubes[idx][:,int(len(cubes[idx][<span class="number">0</span>])*phase[i]),:]</span><br><span class="line">        axes[i][j].imshow(img, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/2019/06/05/luna16-preprocessing/12.png">

<p>5개 큐브에 대하여 axial, sagittal, 그리고 coronal 단면을 각 축의 중심 위치를 기준으로 다섯 단계를 설정하여 출력한 것이다. 축제목을 정하기 귀찮아 단면만 출력되도록 코딩하였지만 직감적으로 연속된 단면이 축에 따라 나열된 것임을 알 수 있다. 앞서 기재한 모든 코드를 subset0 뿐만 아니라 다른 subset에도 적용되도록 작성하면 1차 전처리를 손쉽게 수행할 수 있다.</p>
<h2 id="V-마무리"><a href="#V-마무리" class="headerlink" title="V. 마무리"></a>V. 마무리</h2><p>이 포스트에서는 폐 CT 영상 데이터 세트 및 분석, 전처리에 대한 대략적인 내용을 다루어 보았다. 보편적으로 의료 영상 처리에는 세그먼테이션을 통해 어떤 영역, 예를 들어 분석을 원하는 장기 따위를 표지하는 작업이 선행되는데, 그런 작업이 인간에 의한 특징 추출 작업(handcrafted feature extraction)이라면 딥러닝은 이 작업을 스스로 하기에 우리는 단순히 결절 영역만 크롭하여 데이터 증강 후 모델에 투입시켰었다. 개인적으로 더 고급스러운 전처리가 적용되었더라면 결과는 어떻게 바뀌었을까 궁금하기도 하다. 지금껏 다룬 모든 코드 조각들을 종합한 최종본을 끝으로 포스팅을 마무리한다. 다음 포스트는 2차 전처리에 대하여 다룰 예정이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Author: Seunghyun Kim</span></span><br><span class="line"><span class="comment"># Date: 18 Feb 2019</span></span><br><span class="line"><span class="comment"># Last updated: 21 Feb 2019</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> SimpleITK <span class="keyword">as</span> sitk</span><br><span class="line"><span class="keyword">from</span> scipy.ndimage <span class="keyword">import</span> interpolation</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_real_resize_factor</span><span class="params">(shape, spacing, adj_spacing=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> adj_spacing <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        adj_spacing = list(np.ones_like(shape))</span><br><span class="line">    new_shape = np.round(shape * (spacing / adj_spacing))</span><br><span class="line">    real_resize_factor = new_shape / shape</span><br><span class="line">    <span class="keyword">return</span> real_resize_factor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_resample</span><span class="params">(imgarr, spacing, only_csv)</span>:</span></span><br><span class="line">    real_resize_factor = _real_resize_factor(imgarr.shape, spacing)</span><br><span class="line">    spacing = spacing / real_resize_factor</span><br><span class="line">    <span class="keyword">if</span> only_csv:</span><br><span class="line">        imgarr = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        imgarr = interpolation.zoom(imgarr, real_resize_factor, mode=<span class="string">'nearest'</span>)</span><br><span class="line">    <span class="keyword">return</span> imgarr, spacing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_normalize</span><span class="params">(imgarr, norm_min, norm_max)</span>:</span></span><br><span class="line">    imgarr = np.where(imgarr &lt; norm_min, norm_min, imgarr)</span><br><span class="line">    imgarr = np.where(imgarr &gt; norm_max, norm_max, imgarr)</span><br><span class="line">    imgarr = (imgarr + abs(norm_min)) / (abs(norm_min) + abs(norm_max))</span><br><span class="line">    <span class="keyword">return</span> imgarr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract</span><span class="params">(imgarr, pos, size, margin)</span>:</span></span><br><span class="line">    shape = imgarr.shape</span><br><span class="line">    half_size = np.rint(size / <span class="number">2</span>)</span><br><span class="line">    vmin = (pos - half_size) - margin</span><br><span class="line">    vmin = [np.max([<span class="number">0</span>, int(i)]) <span class="keyword">for</span> i <span class="keyword">in</span> vmin]</span><br><span class="line">    vmax = vmin + size + (margin * <span class="number">2</span>)</span><br><span class="line">    vmax = [np.min([ax, int(i)]) <span class="keyword">for</span> ax, i <span class="keyword">in</span> zip(shape, vmax)]</span><br><span class="line">    <span class="keyword">return</span> imgarr[vmin[<span class="number">0</span>]:vmax[<span class="number">0</span>], vmin[<span class="number">1</span>]:vmax[<span class="number">1</span>], vmin[<span class="number">2</span>]:vmax[<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_wrap</span><span class="params">(cand_arr, size)</span>:</span></span><br><span class="line">    shape = cand_arr.shape</span><br><span class="line">    wrapped = np.ones(size) * np.min(cand_arr)</span><br><span class="line">    vmin = np.rint((size - shape) / <span class="number">2</span>)</span><br><span class="line">    vmin = np.array([int(i) <span class="keyword">for</span> i <span class="keyword">in</span> vmin])</span><br><span class="line">    vmax = vmin + shape</span><br><span class="line">    wrapped[vmin[<span class="number">0</span>]:vmax[<span class="number">0</span>], vmin[<span class="number">1</span>]:vmax[<span class="number">1</span>], vmin[<span class="number">2</span>]:vmax[<span class="number">2</span>]] = cand_arr</span><br><span class="line">    <span class="keyword">return</span> wrapped</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unzip_data</span><span class="params">(input_dir, output_dir)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Unzip all data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    We assume that you have downloaded all the necessary data from</span></span><br><span class="line"><span class="string">    the [LUNA16](https://luna16.grand-challenge.org) website. This</span></span><br><span class="line"><span class="string">    task requires at least 120 Gb of free space and 7-zip package.</span></span><br><span class="line"><span class="string">    If you see that the command is not found when you run the task,</span></span><br><span class="line"><span class="string">    see the following URL: https://www.7-zip.org/</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(output_dir):</span><br><span class="line">        os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line">    zip_files = glob(os.path.join(input_dir, <span class="string">'*.zip'</span>))</span><br><span class="line">    zip_files.sort()</span><br><span class="line">    <span class="keyword">for</span> zip_file <span class="keyword">in</span> tqdm(zip_files):</span><br><span class="line">        os.system(<span class="string">'7z x '</span> + zip_file + <span class="string">' -o'</span> + output_dir + <span class="string">' -aos'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resample_mhd_to_npy</span><span class="params">(input_dir, output_dir, csv_file, norm_min, norm_max,</span></span></span><br><span class="line"><span class="function"><span class="params">                        only_csv=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Resample all mhd to npy.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For preprocessing the data, resamples the coordinate system of</span></span><br><span class="line"><span class="string">    raw files into a voxel-based coordinate system. This task takes</span></span><br><span class="line"><span class="string">    a lot of time, so it is a good idea to save the results. But it</span></span><br><span class="line"><span class="string">    requires at least 290 Gb of free space.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Sometimes you only need a voxel CSV file. If you set the variable</span></span><br><span class="line"><span class="string">    only_csv to True, resample_mhd_to_npy() save only the voxel CSV</span></span><br><span class="line"><span class="string">    file. This takes a short time to calculate.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> only_csv <span class="keyword">and</span> os.path.isdir(output_dir):</span><br><span class="line">        msg = <span class="string">'The output directory already exists. '</span> + \</span><br><span class="line">              <span class="string">'If you want to resample again, delete '</span> + \</span><br><span class="line">              <span class="string">'the output directory and try again.'</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="literal">False</span>, msg</span><br><span class="line"></span><br><span class="line">    Subset = namedtuple(<span class="string">'Subset'</span>, [<span class="string">'path'</span>, <span class="string">'mhd_files'</span>])</span><br><span class="line"></span><br><span class="line">    subset_dirs = glob(os.path.join(input_dir, <span class="string">'subset*'</span>))</span><br><span class="line">    subset_dirs.sort()</span><br><span class="line"></span><br><span class="line">    subsets = []</span><br><span class="line">    <span class="keyword">for</span> subset_dir <span class="keyword">in</span> subset_dirs:</span><br><span class="line">        mhd_files = glob(os.path.join(subset_dir, <span class="string">'*.mhd'</span>))</span><br><span class="line">        subset = Subset(subset_dir, mhd_files)</span><br><span class="line">        subsets.append(subset)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_file_name</span><span class="params">(seriesuid)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">            <span class="keyword">for</span> mhd_file <span class="keyword">in</span> subset.mhd_files:</span><br><span class="line">                <span class="keyword">if</span> seriesuid <span class="keyword">in</span> mhd_file:</span><br><span class="line">                    <span class="keyword">return</span> mhd_file</span><br><span class="line"></span><br><span class="line">    df = pd.read_csv(csv_file)</span><br><span class="line">    df[<span class="string">'file'</span>] = df[<span class="string">'seriesuid'</span>].apply(get_file_name)</span><br><span class="line">    df = df.dropna()</span><br><span class="line">    df[<span class="string">'vcoordX'</span>], df[<span class="string">'vcoordY'</span>], df[<span class="string">'vcoordZ'</span>] = np.nan, np.nan, np.nan</span><br><span class="line">    df[<span class="string">'npy_file'</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">        subset_name = os.path.basename(subset.path)</span><br><span class="line">        new_subset_path = os.path.join(output_dir, subset_name)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> only_csv:</span><br><span class="line">            os.makedirs(new_subset_path)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> mhd_file <span class="keyword">in</span> tqdm(subset.mhd_files):</span><br><span class="line">            df_mhd = df[df[<span class="string">'file'</span>] == mhd_file]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> df_mhd.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                mhd_uid = str(os.path.basename(mhd_file)[:<span class="number">-4</span>].split(<span class="string">'.'</span>)[<span class="number">-1</span>])</span><br><span class="line">                npy_name = subset_name + <span class="string">'_'</span> + mhd_uid + <span class="string">'.npy'</span></span><br><span class="line">                npy_path = os.path.join(new_subset_path, npy_name)</span><br><span class="line"></span><br><span class="line">                img = sitk.ReadImage(mhd_file)</span><br><span class="line">                imgarr = sitk.GetArrayFromImage(img)</span><br><span class="line">                origin = np.array(img.GetOrigin())[::<span class="number">-1</span>]</span><br><span class="line">                spacing = np.array(img.GetSpacing())[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">                imgarr, spacing = _resample(imgarr, spacing, only_csv)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> only_csv:</span><br><span class="line">                    imgarr = _normalize(imgarr, norm_min, norm_max)</span><br><span class="line">                    np.save(npy_path, imgarr)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> i, row <span class="keyword">in</span> df_mhd.iterrows():</span><br><span class="line">                    center = np.array([row[<span class="string">'coordZ'</span>], row[<span class="string">'coordY'</span>], row[<span class="string">'coordX'</span>]])</span><br><span class="line">                    vcenter = np.rint((center - origin) / spacing)</span><br><span class="line">                    df.at[i, <span class="string">'vcoordZ'</span>] = vcenter[<span class="number">0</span>]</span><br><span class="line">                    df.at[i, <span class="string">'vcoordY'</span>] = vcenter[<span class="number">1</span>]</span><br><span class="line">                    df.at[i, <span class="string">'vcoordX'</span>] = vcenter[<span class="number">2</span>]</span><br><span class="line">                    df.at[i, <span class="string">'npy_file'</span>] = npy_name</span><br><span class="line"></span><br><span class="line">    df = df.drop([<span class="string">'seriesuid'</span>, <span class="string">'coordX'</span>, <span class="string">'coordY'</span>, <span class="string">'coordZ'</span>, <span class="string">'file'</span>], axis=<span class="number">1</span>)</span><br><span class="line">    new_csv_file = os.path.join(output_dir, <span class="string">'voxel_'</span> + os.path.basename(csv_file))</span><br><span class="line">    df.to_csv(new_csv_file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_candidate</span><span class="params">(input_dir, output_dir, csv_file, size, margin=<span class="number">0</span>, get_2d=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Extract all candidates from npy files.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This task takes a lot of time, so it is a good idea to save</span></span><br><span class="line"><span class="string">    the results. The required free space depends on the variables</span></span><br><span class="line"><span class="string">    extract_size, margin, and get_2d.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(output_dir):</span><br><span class="line">        msg = <span class="string">'The output directory already exists. '</span> + \</span><br><span class="line">              <span class="string">'If you want to resample again, delete '</span> + \</span><br><span class="line">              <span class="string">'the output directory and try again.'</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="literal">False</span>, msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> type(size) == type([]):</span><br><span class="line">        size = np.array(size)</span><br><span class="line"></span><br><span class="line">    Subset = namedtuple(<span class="string">'Subset'</span>, [<span class="string">'path'</span>, <span class="string">'npy_files'</span>])</span><br><span class="line"></span><br><span class="line">    subset_dirs = glob(os.path.join(input_dir, <span class="string">'subset*'</span>))</span><br><span class="line">    subset_dirs.sort()</span><br><span class="line"></span><br><span class="line">    subsets = []</span><br><span class="line">    <span class="keyword">for</span> subset_dir <span class="keyword">in</span> subset_dirs:</span><br><span class="line">        npy_files = glob(os.path.join(subset_dir, <span class="string">'*.npy'</span>))</span><br><span class="line">        subset = Subset(subset_dir, npy_files)</span><br><span class="line">        subsets.append(subset)</span><br><span class="line"></span><br><span class="line">    df = pd.read_csv(csv_file)</span><br><span class="line">    fill = len(str(len(df)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">        subset_name = os.path.basename(subset.path)</span><br><span class="line">        new_subset_path = os.path.join(output_dir, subset_name)</span><br><span class="line">        os.makedirs(new_subset_path)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> npy_file <span class="keyword">in</span> tqdm(subset.npy_files):</span><br><span class="line">            npy_name = os.path.basename(npy_file)</span><br><span class="line">            df_npy = df[df[<span class="string">'npy_file'</span>] == npy_name]</span><br><span class="line">            imgarr = np.load(npy_file)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i, row <span class="keyword">in</span> df_npy.iterrows():</span><br><span class="line">                vcenter = np.array([row[<span class="string">'vcoordZ'</span>], row[<span class="string">'vcoordY'</span>], row[<span class="string">'vcoordX'</span>]])</span><br><span class="line">                cand_arr = _extract(imgarr, vcenter, size, margin)</span><br><span class="line">                cand_arr = _wrap(cand_arr, size)</span><br><span class="line">                <span class="keyword">if</span> get_2d:</span><br><span class="line">                    cand_arr = cand_arr[int(cand_arr.shape[<span class="number">0</span>]/<span class="number">2</span>)]</span><br><span class="line">                tag_r = <span class="string">'row'</span> + str(i).zfill(fill)</span><br><span class="line">                tag_c = <span class="string">'_cls'</span> + str(row[<span class="string">'class'</span>])</span><br><span class="line">                cand_name = tag_r + tag_c + <span class="string">'.npy'</span></span><br><span class="line">                cand_path = os.path.join(new_subset_path, cand_name)</span><br><span class="line">                np.save(cand_path, cand_arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    warnings.filterwarnings(<span class="string">'ignore'</span>, <span class="string">'.*output shape of zoom.*'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># origin_dir:</span></span><br><span class="line">    <span class="comment">#   The directory path containing the compressed files downloaded from the website.</span></span><br><span class="line">    <span class="comment">#   The compression files we used are listed below:</span></span><br><span class="line">    <span class="comment">#   subset0.zip, ..., subset9.zip, candidates_V2.zip (total 11)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># unzip_dir:</span></span><br><span class="line">    <span class="comment">#   The directory path where the extracted files will be stored.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># resample_dir:</span></span><br><span class="line">    <span class="comment">#   The directory path where resampled data will be stored.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># extract_dir:</span></span><br><span class="line">    <span class="comment">#   The directory path where extracted candidates will be stored.</span></span><br><span class="line">    origin_dir = <span class="string">'/data/datasets/luna16-origin'</span></span><br><span class="line">    unzip_dir = <span class="string">'/data/datasets/luna16-unzip'</span></span><br><span class="line">    resample_dir = <span class="string">'/data/datasets/luna16-resample'</span></span><br><span class="line">    extract_dir = <span class="string">'/data/datasets/luna16-extracted'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 1. Unzip all data.</span></span><br><span class="line">    <span class="comment">#   We assume that you have downloaded all the necessary data from</span></span><br><span class="line">    <span class="comment">#   the [LUNA16](https://luna16.grand-challenge.org) website. This</span></span><br><span class="line">    <span class="comment">#   task requires at least 120 Gb of free space and 7-zip package.</span></span><br><span class="line">    <span class="comment">#   If you see that the command is not found when you run the task,</span></span><br><span class="line">    <span class="comment">#   see the following URL: https://www.7-zip.org/</span></span><br><span class="line">    unzip_data(origin_dir, unzip_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2. Resample all mhd to npy.</span></span><br><span class="line">    <span class="comment">#   For preprocessing the data, resamples the coordinate system of</span></span><br><span class="line">    <span class="comment">#   raw files into a voxel-based coordinate system. This task takes</span></span><br><span class="line">    <span class="comment">#   a lot of time, so it is a good idea to save the results. But it</span></span><br><span class="line">    <span class="comment">#   requires at least 290 Gb of free space.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#   Sometimes you only need a voxel CSV file. If you set the variable</span></span><br><span class="line">    <span class="comment">#   only_csv to True, resample_mhd_to_npy() save only the voxel CSV</span></span><br><span class="line">    <span class="comment">#   file. This takes a short time to calculate.</span></span><br><span class="line">    csv_file = os.path.join(unzip_dir, <span class="string">'candidates_V2.csv'</span>)</span><br><span class="line">    norm_min, norm_max = <span class="number">-1000</span>, <span class="number">400</span></span><br><span class="line">    only_csv = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    resample_mhd_to_npy(unzip_dir, resample_dir, csv_file, norm_min, norm_max, only_csv)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 3. Extract all candidates from npy files.</span></span><br><span class="line">    <span class="comment">#   This task takes a lot of time, so it is a good idea to save the</span></span><br><span class="line">    <span class="comment">#   results. The required free space depends on the variables</span></span><br><span class="line">    <span class="comment">#   extract_size, margin, and get_2d.</span></span><br><span class="line">    voxel_csv_file = os.path.join(resample_dir, <span class="string">'voxel_candidates_V2.csv'</span>)</span><br><span class="line">    extract_size = [<span class="number">56</span>, <span class="number">56</span>, <span class="number">56</span>]</span><br><span class="line"></span><br><span class="line">    extract_candidate(resample_dir, extract_dir, voxel_csv_file, extract_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#main()</span></span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Seunghyun Kim">
            
              <p class="site-author-name" itemprop="name">Seunghyun Kim</p>
              <div class="site-description motion-element" itemprop="description">Hello, World!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">포스트</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">카테고리</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">태그</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/libskim" title="GitHub &rarr; https://github.com/libskim" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="mailto:kimsh.me@gmail.com" title="E-Mail &rarr; mailto:kimsh.me@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Seunghyun Kim</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.1.2</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,0,0" opacity="0.7" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>













  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>




  

  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  



  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
